{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Finetuning experiment: Extract structured data for German law journal editors from website text\n",
    "\n",
    "based on https://github.com/ml-explore/mlx-examples/tree/main/lora\n",
    "\n",
    "Hardware: Mac mini 2023 (M2, 16 GB RAM)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6264ff5d5024ba1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create training data \n",
    "\n",
    "### Download website data\n",
    "\n",
    "This only downloads new content if the list of journals has been changed or already downloaded files have been deleted. To overwrite existing files, use `overwrite=True`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1135fbc8a6ced279"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading Content:   0%|          | 0/130 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7470149ad0534f15bc7158770475355c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 0 web pages.\n"
     ]
    }
   ],
   "source": [
    "from lib.prepare_training_data import download_input_data\n",
    "download_input_data(input_file='data/editors.csv', \n",
    "                    output_dir='data/website-data', \n",
    "                    overwrite=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T09:49:56.822042Z",
     "start_time": "2024-02-28T09:49:56.780283Z"
    }
   },
   "id": "9eb2effc7bfb22f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Instruction prompt\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "434335a9891b27e7"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "system_message =\"\"\"\n",
    "You are a text processing agent. As instructed below, extract information from the provided content in a structured format without discussing reasoning or providing commentary. Only use source text given as input for data extraction unless specifically asked for inference.\n",
    "\"\"\"\n",
    "\n",
    "instruction = \"\"\"\n",
    "Analyze the content from a German law journal's website which follows this instruction. Your task is to identify members of the editorial board (terms to look for: 'Herausgeber', 'Redakteur', 'Schriftleitung') and the advisory board ('Beirat'). For each identified member, extract and organize their information into the following categories: lastname, firstname, title (including academic titles like 'Dr.' or 'Prof. Dr.' and suffixes such as 'LL.M.'), position (their job title, if provided), affiliation, and role. For 'role', infer the role within the journal from the context (options 'Herausgeber', 'Redaktion', 'Schriftleitung', 'Beirat', or an empty string if the role is unknown).\n",
    "\n",
    "- Format the output as a YAML list of dictionaries.\n",
    "- Exclude any dictionary entries for which information is not available or relevant fields are empty.\n",
    "- Ensure the YAML output is strictly valid.\n",
    "\n",
    "Adhere to these guidelines to efficiently and accurately process the following content:\"\n",
    "\"\"\".strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T14:10:39.997135Z",
     "start_time": "2024-02-29T14:10:39.990995Z"
    }
   },
   "id": "b4be7c0872d2fd34"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate training, testing and validation files"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30521e178126b249"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence length:\n",
      " - max: 4730\n",
      " - avg: 1631.2719298245613\n",
      "Longest sequences:\n",
      "AfkKR: 4730\n",
      "StAZ: 3493\n",
      "BB: 3419\n",
      "DÖD: 3236\n",
      "ECFR: 3164\n",
      "AfP: 3157\n",
      "AuA: 3074\n",
      "HRN: 2885\n",
      "DivRuW: 2778\n",
      "DJZ: 2750\n"
     ]
    }
   ],
   "source": [
    "from lib.prepare_training_data import create_training_file\n",
    "\n",
    "def template_fn(prompt: str, answer: str):\n",
    "    return f'<s>[INST]{prompt}[/INST]{answer}</s>'\n",
    "\n",
    "create_training_file(instruction=instruction,\n",
    "                     template_func=template_fn,\n",
    "                     input_file='data/editors/editors.csv', \n",
    "                     output_dir='data/editors', \n",
    "                     content_dir='data/editors/website-data',\n",
    "                     max_chars=6000, max_gt_items=5,\n",
    "                     record_identifier_col=\"journal_abbr\",\n",
    "                     cols_to_remove = ['journal_abbr', 'website', 'retrieved_on'],\n",
    "                     column_to_filter_by='lastname',\n",
    "                     lines_before=2, lines_after=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T11:33:16.024099Z",
     "start_time": "2024-02-29T11:33:14.006597Z"
    }
   },
   "id": "31a2389404720256"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## mistralai/Mistral-7B-v0.2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9dff0d6c779882c"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_MODEL_PATH=mistralai/Mistral-7B-Instruct-v0.2\n",
      "LOCAL_MODEL_PATH=mlx_models/mistralai/Mistral-7B-Instruct-v0.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HF_MODEL_PATH = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "LOCAL_MODEL_PATH = f'mlx_models/{HF_MODEL_PATH}'\n",
    "os.environ['HF_MODEL_PATH'] = HF_MODEL_PATH\n",
    "os.environ['LOCAL_MODEL_PATH'] = LOCAL_MODEL_PATH\n",
    "print(f\"\"\"\n",
    "HF_MODEL_PATH={HF_MODEL_PATH}\n",
    "LOCAL_MODEL_PATH={LOCAL_MODEL_PATH}\n",
    "\"\"\".strip())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T11:45:38.445799Z",
     "start_time": "2024-02-29T11:45:38.433624Z"
    }
   },
   "id": "203bf0c10dd860a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a 4-Bit quantized model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a52bdff5b0eae3bd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python convert.py --hf-path \"$HF_MODEL_PATH\" --mlx-path \"$LOCAL_MODEL_PATH\" -q"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdb9ec6772be0c23"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create adapter with fine-tuned weights"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c46d1d132de28c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python lora.py --train \\\n",
    "    --model \"$LOCAL_MODEL_PATH\" \\\n",
    "    --data data/editors \\\n",
    "    --adapter-file \"$LOCAL_MODEL_PATH/editors.npz\" \\\n",
    "    --iters 600 --batch-size 1 --lora-layers 4 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd1a48e84474aaea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "To run in a separate shell:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4945c07efbb3b4e8"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd mlx/lora\n",
      "python lora.py --train \\\n",
      "    --model mlx_models/mistralai/Mistral-7B-Instruct-v0.2 \\\n",
      "    --data data/editors \\\n",
      "    --adapter-file mlx_models/mistralai/Mistral-7B-Instruct-v0.2/editors.npz \\\n",
      "    --iters 600 --batch-size 1 --lora-layers 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "cd mlx/lora\n",
    "python lora.py --train \\\\\n",
    "    --model {LOCAL_MODEL_PATH} \\\\\n",
    "    --data data/editors \\\\\n",
    "    --adapter-file {LOCAL_MODEL_PATH}/editors.npz \\\\\n",
    "    --iters 600 --batch-size 1 --lora-layers 4 \n",
    "\"\"\".strip())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T11:56:53.290066Z",
     "start_time": "2024-02-29T11:56:53.283755Z"
    }
   },
   "id": "dc9af052b1e9a9e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test the model with adapter"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27ec240d6a886b16"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\r\n",
      "Test loss 0.928, Test ppl 2.529.\r\n"
     ]
    }
   ],
   "source": [
    "!python lora.py --test \\\n",
    "    --model mlx_models/mistralai/Mistral-7B-Instruct-v0.2 \\\n",
    "    --data data/editors \\\n",
    "    --adapter-file mlx_models/mistralai/Mistral-7B-Instruct-v0.2/editors.npz"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T13:52:03.129556Z",
     "start_time": "2024-02-29T13:45:37.469459Z"
    }
   },
   "id": "a66ab3a823260361"
  },
  {
   "cell_type": "markdown",
   "source": [
    "last result:\n",
    "Test loss 0.928, Test ppl 2.529."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bab8168bd116d38"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prompt it with an example"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7e42a5574068ba9"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "prompt=f\"\"\"\n",
    "{system_message}\n",
    "\n",
    "{instruction}\n",
    "\n",
    "### CONTENT\n",
    "\n",
    "Herausgeber:\n",
    "Prof. Dr. Stefan Knesebeck, Universität Wuppertal\n",
    "Prof. Dr. Dr. h.c. Fritz M. Müller LL.M.(Yale), Universität Wanne-Eickel\n",
    "RA Prof. Dr. Vera Valentin, Hochschule für Recht und Sport Edingen\n",
    "Prof. Dr. Dr. h.c. Rita Rosenbaum, Universität Tupfingen\n",
    "Dr. Ingo Gonzalo de Sanchez, Vorsitzender Richter am Oberlandesgericht Rostock\n",
    "Redaktion:\n",
    "RA Adam Gengelbach, Unterhachingen\n",
    "Ass. iur. Petra Priem, Herrenchiemsee\n",
    "\n",
    "### END OF CONTENT\n",
    "\"\"\".strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T14:16:06.332197Z",
     "start_time": "2024-02-29T14:16:06.326960Z"
    }
   },
   "id": "8d316a1e7570f1d4"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a text processing agent. As instructed below, extract information from the provided content in a structured format without discussing reasoning or providing commentary. Only use source text given as input for data extraction unless specifically asked for inference.\n",
      "\n",
      "\n",
      "Analyze the content from a German law journal's website which follows this instruction. Your task is to identify members of the editorial board (terms to look for: 'Herausgeber', 'Redakteur', 'Schriftleitung') and the advisory board ('Beirat'). For each identified member, extract and organize their information into the following categories: lastname, firstname, title (including academic titles like 'Dr.' or 'Prof. Dr.' and suffixes such as 'LL.M.'), position (their job title, if provided), affiliation, and role. For 'role', infer the role within the journal from the context (options 'Herausgeber', 'Redaktion', 'Schriftleitung', 'Beirat', or an empty string if the role is unknown).\n",
      "\n",
      "- Format the output as a YAML list of dictionaries.\n",
      "- Exclude any dictionary entries for which information is not available or relevant fields are empty.\n",
      "- Ensure the YAML output is strictly valid.\n",
      "\n",
      "Adhere to these guidelines to efficiently and accurately process the following content:\"\n",
      "\n",
      "### CONTENT\n",
      "\n",
      "Herausgeber:\n",
      "Prof. Dr. Stefan Knesebeck, Universität Wuppertal\n",
      "Prof. Dr. Dr. h.c. Fritz M. Müller LL.M.(Yale), Universität Wanne-Eickel\n",
      "RA Prof. Dr. Vera Valentin, Hochschule für Recht und Sport Edingen\n",
      "Prof. Dr. Dr. h.c. Rita Rosenbaum, Universität Tupfingen\n",
      "Dr. Ingo Gonzalo de Sanchez, Vorsitzender Richter am Oberlandesgericht Rostock\n",
      "Redaktion:\n",
      "RA Adam Gengelbach, Unterhachingen\n",
      "Ass. iur. Petra Priem, Herrenchiemsee\n",
      "\n",
      "### END OF CONTENT\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T14:16:07.677659Z",
     "start_time": "2024-02-29T14:16:07.672036Z"
    }
   },
   "id": "3e7a823a9f4a35d9"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "### OUTPUT\r\n",
      "\r\n",
      "- lastname: Knesebeck\r\n",
      "  firstname: Stefan\r\n",
      "  title: Prof. Dr.\r\n",
      "  position: Herausgeber\r\n",
      "  affiliation: Universität Wuppertal\r\n",
      "  role: Herausgeber\r\n",
      "- lastname: Müller\r\n",
      "  firstname: Fritz M.\r\n",
      "  title: Prof. Dr. Dr. h.c.\r\n",
      "  position: Herausgeber\r\n",
      "  affiliation: Universität Wanne-Eickel\r\n",
      "  role: Herausgeber\r\n",
      "- lastname: Valentin\r\n",
      "  firstname: Vera\r\n",
      "  title: RA Prof. Dr.\r\n",
      "  position: Redaktion\r\n",
      "  affiliation: Hochschule für Recht und Sport Edingen\r\n",
      "  role: Redaktion\r\n",
      "- lastname: Rosenbaum\r\n",
      "  firstname: Rita\r\n",
      "  title: Prof. Dr. Dr. h.c.\r\n",
      "  position: Herausgeber\r\n",
      "  affiliation: Universität Tupfingen\r\n",
      "  role: Herausgeber\r\n",
      "- lastname: Gonzalo de Sanchez\r\n",
      "  firstname: Ingo\r\n",
      "  title: Dr.\r\n",
      "  position: Vorsitzender Richter am Oberlandesgericht Rostock\r\n",
      "  affiliation: Empty\r\n",
      "  role: Empty\r\n",
      "\r\n",
      "Generation took 65.16657900810242 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "os.environ['LLM_PROMPT'] = prompt\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "start_time = time.time()\n",
    "!python lora.py \\\n",
    "    --model mlx_models/mistralai/Mistral-7B-Instruct-v0.2 \\\n",
    "    --adapter-file mlx_models/mistralai/Mistral-7B-Instruct-v0.2/editors.npz \\\n",
    "    --max-tokens 400 \\\n",
    "    --temp 0 \\\n",
    "    --prompt \"$LLM_PROMPT\"\n",
    "print(f'Generation took {time.time() - start_time} seconds')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T14:17:15.637298Z",
     "start_time": "2024-02-29T14:16:10.463466Z"
    }
   },
   "id": "1ea4b39f35c09268"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# mlx-community/quantized-gemma-7b-it"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1b0c8c8648906b7"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a229bb7e24b3445fa000e2b8f9b6ec81"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```yaml\n",
      "- lastname: Knesebeck\n",
      "  firstname: Stefan\n",
      "  title: Prof. Dr.\n",
      "  position:\n",
      "  affiliation: Universität Wuppertal\n",
      "  role:Herausgeber\n",
      "\n",
      "- lastname: Müller\n",
      "  firstname: Dr. Dr. h.c. Fritz M.\n",
      "  title: Prof. Dr. LL.M.(Yale)\n",
      "  position:\n",
      "  affiliation: Universität Wanne-Eickel\n",
      "  role:Herausgeber\n",
      "\n",
      "- lastname: Valentin\n",
      "  firstname: RA Prof. Dr. Vera\n",
      "  title: Prof. Dr.\n",
      "  position:\n",
      "  affiliation: Hochschule für Recht und Sport Edingen\n",
      "  role:Herausgeber\n",
      "\n",
      "- lastname: Rosenbaum\n",
      "  firstname: Prof. Dr. Dr. h.c. Rita\n",
      "  title: Prof. Dr.\n",
      "  position:\n",
      "  affiliation: Universität Tupfingen\n",
      "  role:Herausgeber\n",
      "\n",
      "- lastname: Gonzalo de Sanchez\n",
      "  firstname: Dr. Ingo\n",
      "  title:\n",
      "  position: Vorsitzender Richter am Oberlandesgericht Rostock\n",
      "  role:\n",
      "\n",
      "- lastname: Gengelbach\n",
      "  firstname: RA Adam\n",
      "  title:\n",
      "  position:\n",
      "  affiliation: Unterhachingen\n",
      "  role:\n",
      "\n",
      "- lastname: Priem\n",
      "  firstname: Ass. iur. Petra\n",
      "  title:\n",
      "  position:\n",
      "  affiliation: Herrenchiemsee\n",
      "  role:\n",
      "```\n",
      "\n",
      "This is the requested output. Please extract the requested\n",
      "Generation took 35.79903483390808 seconds\n"
     ]
    }
   ],
   "source": [
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "from mlx_lm import load, generate\n",
    "import time\n",
    "\n",
    "model, tokenizer = load(\"mlx-community/quantized-gemma-7b-it\")\n",
    "start_time = time.time()\n",
    "response = generate(model, tokenizer, prompt=prompt, verbose=False, max_tokens=300)\n",
    "print(response)\n",
    "print(f'Generation took {time.time() - start_time} seconds')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T08:38:10.003959Z",
     "start_time": "2024-02-29T08:37:23.119783Z"
    }
   },
   "id": "89e1a05fc3b6e435"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d21183bc0271340a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
