{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Finetuning experiment: Extract structured data for German law journal editors from website text\n",
    "\n",
    "based on https://github.com/ml-explore/mlx-examples/tree/main/lora\n",
    "\n",
    "Hardware: Mac mini 2023 (M2, 16 GB RAM)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6264ff5d5024ba1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparation\n",
    "\n",
    "### Download website data\n",
    "\n",
    "This only downloads new content if the list of journals has been changed or already downloaded files have been deleted. To overwrite existing files, use `overwrite=True`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1135fbc8a6ced279"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading Content:   0%|          | 0/130 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7470149ad0534f15bc7158770475355c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 0 web pages.\n"
     ]
    }
   ],
   "source": [
    "from lib.prepare_training_data import download_input_data\n",
    "download_input_data(input_file='data/editors.csv', \n",
    "                    output_dir='data/website-data', \n",
    "                    overwrite=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T09:49:56.822042Z",
     "start_time": "2024-02-28T09:49:56.780283Z"
    }
   },
   "id": "9eb2effc7bfb22f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prompt and test data for all experiments\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "434335a9891b27e7"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "system_message =\"\"\"\n",
    "You are a text processing agent. As instructed below, extract information from the provided content in a structured format without discussing reasoning or providing commentary. Only use source text given as input for data extraction unless specifically asked for inference.\n",
    "\"\"\"\n",
    "\n",
    "instruction = \"\"\"\n",
    "Analyze content from a German law journal's website. Your task is to identify members of the editorial board (terms to look for: 'Herausgeber', 'Redakteur', 'Schriftleitung') and the advisory board ('Beirat'). For each identified member, extract and organize their information into the following categories: lastname, firstname, title (including academic titles like 'Dr.' or 'Prof. Dr.' and suffixes such as 'LL.M.'), position (their job title, if provided), affiliation, and role. For 'role', infer the role within the journal from the context (options 'Herausgeber', 'Redaktion', 'Schriftleitung', 'Beirat', or an empty string if the role is unknown).\n",
    "\n",
    "- Format the output as a YAML list of dictionaries.\n",
    "- Exclude any dictionary entries for which information is not available or relevant fields are empty.\n",
    "- Ensure the YAML output is strictly valid. It must be a list of dictionaries. \n",
    "\"\"\"\n",
    "\n",
    "example = \"\"\"\n",
    "Here is an example:\n",
    "\n",
    "```yaml\n",
    "- lastname: Mustermann\n",
    "  firstname: Martina\n",
    "  title: Dr.\n",
    "  position: Vorsitzender Richterin\n",
    "  affiliation: Oberlandesgericht Buxtehude\n",
    "  role: Herausgeber\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "epilog=\"\"\"\n",
    "Adhere to these guidelines to efficiently and accurately process the following content:\"\n",
    "\"\"\"\n",
    "\n",
    "test_data = \"\"\"\n",
    "Herausgeber:\n",
    "Prof. Dr. Stefan Knesebeck, Universität Wuppertal\n",
    "Prof. Dr. Dr. h.c. Fritz M. Müller LL.M.(Yale), Universität Wanne-Eickel\n",
    "RA Prof. Dr. Vera Valentin, Hochschule für Recht und Sport Edingen\n",
    "Prof. Dr. Dr. h.c. Rita Rosenbaum, Universität Tupfingen\n",
    "Dr. Ingo Gonzalo de Sanchez, Vorsitzender Richter am Oberlandesgericht Rostock\n",
    "Redaktion:\n",
    "RA Adam Gengelbach, Unterhachingen\n",
    "Ass. iur. Petra Priem, Herrenchiemsee\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T14:33:04.365287Z",
     "start_time": "2024-03-02T14:33:04.358090Z"
    }
   },
   "id": "b4be7c0872d2fd34"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## mistralai/Mistral-7B-v0.2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9dff0d6c779882c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set paths for model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9ba088a74f8c557"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_MODEL_PATH=mistralai/Mistral-7B-Instruct-v0.2\n",
      "LOCAL_MODEL_PATH=mlx_models/mistralai/Mistral-7B-Instruct-v0.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HF_MODEL_PATH = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "LOCAL_MODEL_PATH = f'mlx_models/{HF_MODEL_PATH}'\n",
    "os.environ['HF_MODEL_PATH'] = HF_MODEL_PATH\n",
    "os.environ['LOCAL_MODEL_PATH'] = LOCAL_MODEL_PATH\n",
    "print(f\"\"\"\n",
    "HF_MODEL_PATH={HF_MODEL_PATH}\n",
    "LOCAL_MODEL_PATH={LOCAL_MODEL_PATH}\n",
    "\"\"\".strip())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T08:55:33.087209Z",
     "start_time": "2024-03-01T08:55:33.080961Z"
    }
   },
   "id": "203bf0c10dd860a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a 4-Bit quantized model if necessary"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a52bdff5b0eae3bd"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "![ -d \"$LOCAL_MODEL_PATH\" ] || python convert.py --hf-path \"$HF_MODEL_PATH\" --mlx-path \"$LOCAL_MODEL_PATH\" -q"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T06:51:00.898588Z",
     "start_time": "2024-03-01T06:51:00.764741Z"
    }
   },
   "id": "fdb9ec6772be0c23"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate training, testing and validation files"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30521e178126b249"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of generated sequences:\n",
      " - max: 5446\n",
      " - avg: 2202.035087719298\n",
      "Longest sequences:\n",
      "FoR: 5446\n",
      "DÖD: 4559\n",
      "GLJ: 4153\n",
      "BKK: 4078\n",
      "AcP: 3960\n",
      "AuA: 3656\n",
      "HRN: 3467\n",
      "DSB: 3433\n",
      "DivRuW: 3360\n",
      "AuAS: 3272\n"
     ]
    }
   ],
   "source": [
    "from lib.prepare_training_data import create_training_file\n",
    "import sys\n",
    "\n",
    "mistral_ft_instruction = f\"\"\"\n",
    "# instruction\n",
    "{system_message}\n",
    "# user\n",
    "{instruction}\n",
    "{epilog}\n",
    "# content\n",
    "\"\"\"\n",
    "\n",
    "# the template function receives the instruction, the content to be analyzed, and the expected answer\n",
    "def template_fn(instruction: str, content: str, answer: str):\n",
    "    return f'<s>[INST]{instruction}{content}[/INST]{answer}</s>'\n",
    "\n",
    "create_training_file(instruction=mistral_ft_instruction,\n",
    "                     template_func=template_fn,\n",
    "                     input_file='data/editors/editors.csv', \n",
    "                     output_dir='data/editors/mistral', \n",
    "                     content_dir='data/editors/website-data',\n",
    "                     max_chars=6000, max_gt_items=5,\n",
    "                     record_identifier_col=\"journal_abbr\",\n",
    "                     cols_to_remove = ['journal_abbr', 'website', 'retrieved_on'],\n",
    "                     column_to_filter_by='lastname',\n",
    "                     lines_before=2, lines_after=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T18:09:22.948780Z",
     "start_time": "2024-03-01T18:09:21.794696Z"
    }
   },
   "id": "31a2389404720256"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# instruction\n",
      "\n",
      "You are a text processing agent. As instructed below, extract information from the provided content in a structured format without discussing reasoning or providing commentary. Only use source text given as input for data extraction unless specifically asked for inference.\n",
      "\n",
      "# user\n",
      "\n",
      "Analyze content from a German law journal's website. Your task is to identify members of the editorial board (terms to look for: 'Herausgeber', 'Redakteur', 'Schriftleitung') and the advisory board ('Beirat'). For each identified member, extract and organize their information into the following categories: lastname, firstname, title (including academic titles like 'Dr.' or 'Prof. Dr.' and suffixes such as 'LL.M.'), position (their job title, if provided), affiliation, and role. For 'role', infer the role within the journal from the context (options 'Herausgeber', 'Redaktion', 'Schriftleitung', 'Beirat', or an empty string if the role is unknown).\n",
      "\n",
      "- Format the output as a YAML list of dictionaries.\n",
      "- Exclude any dictionary entries for which information is not available or relevant fields are empty.\n",
      "- Ensure the YAML output is strictly valid. It must be a list of dictionaries. \n",
      "\n",
      "\n",
      "Adhere to these guidelines to efficiently and accurately process the following content:\"\n",
      "\n",
      "# content\n"
     ]
    }
   ],
   "source": [
    "print(mistral_ft_instruction)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-01T08:54:59.402009Z"
    }
   },
   "id": "6181ba9486346975"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Finetuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c46d1d132de28c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python lora.py --train \\\n",
    "    --model \"$LOCAL_MODEL_PATH\" \\\n",
    "    --data data/editors/mistral \\\n",
    "    --adapter-file \"$LOCAL_MODEL_PATH/editors.npz\" \\\n",
    "    --iters 600 --batch-size 1 --lora-layers 4 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd1a48e84474aaea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "To run in a separate shell:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4945c07efbb3b4e8"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd mlx/lora\n",
      "python lora.py --train \\\n",
      "    --model mlx_models/mistralai/Mistral-7B-Instruct-v0.2 \\\n",
      "    --data data/editors/mistral \\\n",
      "    --adapter-file mlx_models/mistralai/Mistral-7B-Instruct-v0.2/editors.npz \\\n",
      "    --iters 600 --batch-size 1 --lora-layers 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "cd mlx/lora\n",
    "python lora.py --train \\\\\n",
    "    --model {LOCAL_MODEL_PATH} \\\\\n",
    "    --data data/editors/mistral \\\\\n",
    "    --adapter-file {LOCAL_MODEL_PATH}/editors.npz \\\\\n",
    "    --iters 600 --batch-size 1 --lora-layers 4 \n",
    "\"\"\".strip())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T08:56:05.078068Z",
     "start_time": "2024-03-01T08:56:05.068770Z"
    }
   },
   "id": "dc9af052b1e9a9e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training loss: ~0.8, ~90 Tokens/sec "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f3bb7b9404da7e7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27ec240d6a886b16"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(39031) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\r\n",
      "Test loss 0.800, Test ppl 2.226.\r\n"
     ]
    }
   ],
   "source": [
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "!python lora.py --test \\\n",
    "    --model mlx_models/mistralai/Mistral-7B-Instruct-v0.2 \\\n",
    "    --data data/editors/mistral \\\n",
    "    --adapter-file mlx_models/mistralai/Mistral-7B-Instruct-v0.2/editors.npz"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T11:01:07.398754Z",
     "start_time": "2024-03-01T10:54:10.548652Z"
    }
   },
   "id": "a66ab3a823260361"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Result:\n",
    " 600 iters: Test loss 0.800, Test ppl 2.226\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bab8168bd116d38"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Manual test prompt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7e42a5574068ba9"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "prompt=f\"\"\"\n",
    "### SYSTEM\n",
    "{system_message}\n",
    "### USER\n",
    "{instruction}\n",
    "{example}\n",
    "### CONTENT\n",
    "{test_data}\n",
    "### END OF CONTENT\n",
    "\"\"\".strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T11:02:00.768988Z",
     "start_time": "2024-03-01T11:02:00.736721Z"
    }
   },
   "id": "8d316a1e7570f1d4"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SYSTEM\n",
      "\n",
      "You are a text processing agent. As instructed below, extract information from the provided content in a structured format without discussing reasoning or providing commentary. Only use source text given as input for data extraction unless specifically asked for inference.\n",
      "\n",
      "### USER\n",
      "\n",
      "Analyze content from a German law journal's website. Your task is to identify members of the editorial board (terms to look for: 'Herausgeber', 'Redakteur', 'Schriftleitung') and the advisory board ('Beirat'). For each identified member, extract and organize their information into the following categories: lastname, firstname, title (including academic titles like 'Dr.' or 'Prof. Dr.' and suffixes such as 'LL.M.'), position (their job title, if provided), affiliation, and role. For 'role', infer the role within the journal from the context (options 'Herausgeber', 'Redaktion', 'Schriftleitung', 'Beirat', or an empty string if the role is unknown).\n",
      "\n",
      "- Format the output as a YAML list of dictionaries.\n",
      "- Exclude any dictionary entries for which information is not available or relevant fields are empty.\n",
      "- Ensure the YAML output is strictly valid. It must be a list of dictionaries. \n",
      "\n",
      "\n",
      "Here is an example:\n",
      "\n",
      "```yaml\n",
      "- lastname: Mustermann\n",
      "  firstname: Martina\n",
      "  title: Dr.\n",
      "  position: Vorsitzender Richterin\n",
      "  affiliation: Oberlandesgericht Buxtehude\n",
      "  role: Herausgeber\n",
      "```\n",
      "\n",
      "### CONTENT\n",
      "\n",
      "Herausgeber:\n",
      "Prof. Dr. Stefan Knesebeck, Universität Wuppertal\n",
      "Prof. Dr. Dr. h.c. Fritz M. Müller LL.M.(Yale), Universität Wanne-Eickel\n",
      "RA Prof. Dr. Vera Valentin, Hochschule für Recht und Sport Edingen\n",
      "Prof. Dr. Dr. h.c. Rita Rosenbaum, Universität Tupfingen\n",
      "Dr. Ingo Gonzalo de Sanchez, Vorsitzender Richter am Oberlandesgericht Rostock\n",
      "Redaktion:\n",
      "RA Adam Gengelbach, Unterhachingen\n",
      "Ass. iur. Petra Priem, Herrenchiemsee\n",
      "\n",
      "### END OF CONTENT\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T11:02:02.619009Z",
     "start_time": "2024-03-01T11:02:02.611281Z"
    }
   },
   "id": "3e7a823a9f4a35d9"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(39255) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "- lastname: Knesebeck\r\n",
      "  firstname: Stefan\r\n",
      "  title: Prof. Dr.\r\n",
      "  position: Universität Wuppertal\r\n",
      "  affiliation: Universität Wuppertal\r\n",
      "  role: Herausgeber\r\n",
      "- lastname: Müller\r\n",
      "  firstname: Fritz M.\r\n",
      "  title: Prof. Dr. Dr. h.c. LL.M.(Yale)\r\n",
      "  position: Universität Wanne-Eickel\r\n",
      "  affiliation: Universität Wanne-Eickel\r\n",
      "  role: Herausgeber\r\n",
      "- lastname: Valentin\r\n",
      "  firstname: Vera\r\n",
      "  title: Prof. Dr.\r\n",
      "  position: Hochschule für Recht und Sport Edingen\r\n",
      "  affiliation: Hochschule für Recht und Sport Edingen\r\n",
      "  role: Redaktion\r\n",
      "- lastname: Rosenbaum\r\n",
      "  firstname: Rita\r\n",
      "  title: Prof. Dr. Dr. h.c.\r\n",
      "  position: Universität Tupfingen\r\n",
      "  affiliation: Universität Tupfingen\r\n",
      "  role: Herausgeber\r\n",
      "- lastname: Gonzalo de Sanchez\r\n",
      "  firstname: Ingo\r\n",
      "  title: Dr.\r\n",
      "  position: Vorsitzender Richter am Oberlandesgericht Rostock\r\n",
      "  affiliation: Oberlandesgericht Rostock\r\n",
      "  role: Herausgeber\r\n",
      "- lastname: Gengelbach\r\n",
      "  firstname: Adam\r\n",
      "  title: RA\r\n",
      "  position: Unterhachingen\r\n",
      "  affiliation: Unterhachingen\r\n",
      "  role: Redaktion\r\n",
      "- lastname: Priem\r\n",
      "  firstname: Petra\r\n",
      "  title: Ass. iur.\r\n",
      "  position: Herrenchiemsee\r\n",
      "  affiliation: Herrenchiemsee\r\n",
      "  role: Redaktion\r\n",
      "Generation took 87.13131785392761 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "os.environ['LLM_PROMPT'] = prompt\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "start_time = time.time()\n",
    "!python lora.py \\\n",
    "    --model mlx_models/mistralai/Mistral-7B-Instruct-v0.2 \\\n",
    "    --adapter-file mlx_models/mistralai/Mistral-7B-Instruct-v0.2/editors.npz \\\n",
    "    --max-tokens 400 \\\n",
    "    --temp 0 \\\n",
    "    --prompt \"$LLM_PROMPT\"\n",
    "print(f'Generation took {time.time() - start_time} seconds')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T11:03:35.866850Z",
     "start_time": "2024-03-01T11:02:08.711417Z"
    }
   },
   "id": "1ea4b39f35c09268"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## mlx-community/quantized-gemma-7b-it\n",
    "\n",
    "This model can be directly downloaded from HF, no conversion necessary\n",
    "\n",
    "based on https://gist.github.com/alexweberk/635431b5c5773efd6d1755801020429f"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1b0c8c8648906b7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Zero-shot"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c5659b8c268e72f"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bae72524d20d4664976cf6a661221488"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schriftleitung:\n",
      "Dr. Martin Schmidt, Berlin\n",
      "Beirat:\n",
      "Dr. Hans-Peter Kaulitz, Berlin\n",
      "Dr. Franz-Josef Schmidt, München\n",
      "\n",
      "```\n",
      "\n",
      "**Expected Output:**\n",
      "\n",
      "```yaml\n",
      "- lastname: Knesebeck\n",
      "  firstname: Stefan\n",
      "  title: Prof. Dr.\n",
      "  position: N/A\n",
      "  affiliation: Universität Wuppertal\n",
      "  role: Herausgeber\n",
      "\n",
      "- lastname: Müller\n",
      "  firstname: Fritz M.\n",
      "  title: Prof. Dr. Dr. h.c. LL.M.(Yale)\n",
      "  position: N/A\n",
      "  affiliation: Universität Wanne-Eickel\n",
      "  role: Herausgeber\n",
      "\n",
      "- lastname: Valentin\n",
      "  firstname: Vera\n",
      "  title: RA Prof. Dr.\n",
      "  position: N/A\n",
      "  affiliation: Hochschule für Recht und Sport Edingen\n",
      "  role: N/A\n",
      "\n",
      "- lastname: Rosenbaum\n",
      "  firstname: Rita\n",
      "  title: Prof. Dr. Dr. h.c.\n",
      "  position: N/A\n",
      "  affiliation: Universität Tupfingen\n",
      "  role: N/A\n",
      "\n",
      "- lastname: Gonzalo de Sanchez\n",
      "  firstname: Ingo\n",
      "  title: Dr.\n",
      "  position: Vorsitzender Richter am Oberlandesgericht Rostock\n",
      "  affiliation: Oberlandesgericht Rostock\n",
      "  role: N/A\n",
      "\n",
      "- lastname: Gengelbach\n",
      "  firstname: Adam\n",
      "  title: RA\n",
      "  position: N/A\n",
      "Generation took 50.564462184906006 seconds\n"
     ]
    }
   ],
   "source": [
    "from mlx_lm import load, generate\n",
    "import time\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "prompt = f\"\"\"\n",
    "#### Instructions\n",
    "{system_message}\n",
    "### User\n",
    "{instruction}\n",
    "{example}\n",
    "{epilog}\n",
    "\n",
    "{test_data}\n",
    "\n",
    "\"\"\".strip()\n",
    "\n",
    "model, tokenizer = load(\"mlx-community/quantized-gemma-7b-it\")\n",
    "start_time = time.time()\n",
    "response = generate(model, tokenizer, prompt=prompt, verbose=False, max_tokens=300, temp=0)\n",
    "print(response)\n",
    "print(f'Generation took {time.time() - start_time} seconds')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T11:12:27.907289Z",
     "start_time": "2024-03-01T11:11:27.618623Z"
    }
   },
   "id": "89e1a05fc3b6e435"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate dataset\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e48938d56b99848c"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of generated sequences:\n",
      " - max: 4816\n",
      " - avg: 2273.424778761062\n",
      "Longest sequences:\n",
      "JurBüro: 4816\n",
      "AusR: 4697\n",
      "AcP: 4010\n",
      "AW-Prax: 3880\n",
      "DÖD: 3870\n",
      "DivRuW: 3867\n",
      "AuA: 3706\n",
      "StAZ: 3601\n",
      "ANA-ZAR: 3361\n",
      "AuAS: 3322\n"
     ]
    }
   ],
   "source": [
    "from lib.prepare_training_data import create_training_file\n",
    "\n",
    "gemma_instruction = f\"\"\"\n",
    "# Instructions\n",
    "{system_message}\n",
    "# User\n",
    "{instruction}\n",
    "{epilog}'\n",
    "\"\"\".strip()\n",
    "\n",
    "def template_fn(instruction: str, content: str, answer: str):\n",
    "    return f'<bos><start_of_turn>user\\n{instruction}\\n\\n{content}<end_of_turn>\\n<start_of_turn>model\\n{answer}<end_of_turn><eos>'\n",
    "\n",
    "create_training_file(instruction=gemma_instruction,\n",
    "                     template_func=template_fn,\n",
    "                     input_file='data/editors/editors.csv',\n",
    "                     output_dir='data/editors/gemma',\n",
    "                     content_dir='data/editors/website-data',\n",
    "                     max_chars=6000, max_gt_items=5,\n",
    "                     record_identifier_col=\"journal_abbr\",\n",
    "                     cols_to_remove=['journal_abbr', 'website', 'retrieved_on'],\n",
    "                     column_to_filter_by='lastname',\n",
    "                     lines_before=2, lines_after=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-01T18:10:08.910617Z",
     "start_time": "2024-03-01T18:10:07.794209Z"
    }
   },
   "id": "8d61e8cf63aa5965"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Finetuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55ac22c3a4e1305e"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model\r\n",
      "Fetching 8 files: 100%|██████████████████████████| 8/8 [00:00<00:00, 389.29it/s]\r\n",
      "Total parameters 1998.171M\r\n",
      "Trainable parameters 0.459M\r\n",
      "Loading datasets\r\n",
      "Training\r\n",
      "Starting training..., iters: 600\r\n",
      "Iter 1: Val loss 6.064, Val took 144.925s\r\n",
      "Iter 10: Train loss 5.106, Learning Rate 1.000e-05, It/sec 0.085, Tokens/sec 60.820, Trained Tokens 7127\r\n",
      "Iter 20: Train loss 4.203, Learning Rate 1.000e-05, It/sec 0.063, Tokens/sec 49.259, Trained Tokens 14895\r\n",
      "Iter 30: Train loss 3.695, Learning Rate 1.000e-05, It/sec 0.086, Tokens/sec 51.924, Trained Tokens 20904\r\n",
      "Iter 40: Train loss 3.638, Learning Rate 1.000e-05, It/sec 0.125, Tokens/sec 60.230, Trained Tokens 25739\r\n",
      "Iter 50: Train loss 3.091, Learning Rate 1.000e-05, It/sec 0.077, Tokens/sec 51.838, Trained Tokens 32501\r\n",
      "Iter 60: Train loss 2.691, Learning Rate 1.000e-05, It/sec 0.086, Tokens/sec 56.203, Trained Tokens 39053\r\n",
      "Iter 70: Train loss 2.525, Learning Rate 1.000e-05, It/sec 0.061, Tokens/sec 45.969, Trained Tokens 46546\r\n",
      "Iter 80: Train loss 2.313, Learning Rate 1.000e-05, It/sec 0.096, Tokens/sec 55.637, Trained Tokens 52342\r\n",
      "Iter 90: Train loss 1.986, Learning Rate 1.000e-05, It/sec 0.077, Tokens/sec 51.038, Trained Tokens 58944\r\n",
      "Iter 100: Train loss 1.932, Learning Rate 1.000e-05, It/sec 0.088, Tokens/sec 56.251, Trained Tokens 65370\r\n",
      "Iter 100: Saved adapter weights to checkpoints/100_editors.npz.\r\n",
      "Iter 110: Train loss 1.745, Learning Rate 1.000e-05, It/sec 0.073, Tokens/sec 49.590, Trained Tokens 72183\r\n",
      "Iter 120: Train loss 1.531, Learning Rate 1.000e-05, It/sec 0.108, Tokens/sec 57.670, Trained Tokens 77506\r\n",
      "Iter 130: Train loss 1.817, Learning Rate 1.000e-05, It/sec 0.090, Tokens/sec 56.202, Trained Tokens 83737\r\n",
      "Iter 140: Train loss 1.358, Learning Rate 1.000e-05, It/sec 0.099, Tokens/sec 59.363, Trained Tokens 89733\r\n",
      "Iter 150: Train loss 1.517, Learning Rate 1.000e-05, It/sec 0.073, Tokens/sec 49.477, Trained Tokens 96513\r\n",
      "Iter 160: Train loss 1.524, Learning Rate 1.000e-05, It/sec 0.077, Tokens/sec 49.295, Trained Tokens 102887\r\n",
      "Iter 170: Train loss 1.316, Learning Rate 1.000e-05, It/sec 0.071, Tokens/sec 50.801, Trained Tokens 109993\r\n",
      "Iter 180: Train loss 1.440, Learning Rate 1.000e-05, It/sec 0.092, Tokens/sec 55.542, Trained Tokens 116060\r\n",
      "Iter 190: Train loss 1.402, Learning Rate 1.000e-05, It/sec 0.077, Tokens/sec 53.860, Trained Tokens 123028\r\n",
      "Iter 200: Train loss 1.578, Learning Rate 1.000e-05, It/sec 0.069, Tokens/sec 53.572, Trained Tokens 130758\r\n",
      "Iter 200: Val loss 1.449, Val took 136.326s\r\n",
      "Iter 200: Saved adapter weights to checkpoints/200_editors.npz.\r\n",
      "Iter 210: Train loss 1.403, Learning Rate 1.000e-05, It/sec 0.068, Tokens/sec 48.232, Trained Tokens 137872\r\n",
      "Iter 220: Train loss 1.596, Learning Rate 1.000e-05, It/sec 0.079, Tokens/sec 55.729, Trained Tokens 144886\r\n",
      "Iter 230: Train loss 1.324, Learning Rate 1.000e-05, It/sec 0.097, Tokens/sec 57.306, Trained Tokens 150820\r\n",
      "Iter 240: Train loss 1.308, Learning Rate 1.000e-05, It/sec 0.090, Tokens/sec 55.030, Trained Tokens 156927\r\n",
      "Iter 250: Train loss 1.394, Learning Rate 1.000e-05, It/sec 0.087, Tokens/sec 58.270, Trained Tokens 163638\r\n",
      "Iter 260: Train loss 1.424, Learning Rate 1.000e-05, It/sec 0.085, Tokens/sec 57.969, Trained Tokens 170473\r\n",
      "Iter 270: Train loss 1.299, Learning Rate 1.000e-05, It/sec 0.081, Tokens/sec 42.263, Trained Tokens 175687\r\n",
      "Iter 280: Train loss 1.489, Learning Rate 1.000e-05, It/sec 0.055, Tokens/sec 45.052, Trained Tokens 183919\r\n",
      "Iter 290: Train loss 1.248, Learning Rate 1.000e-05, It/sec 0.081, Tokens/sec 53.325, Trained Tokens 190540\r\n",
      "Iter 300: Train loss 1.277, Learning Rate 1.000e-05, It/sec 0.077, Tokens/sec 52.184, Trained Tokens 197354\r\n",
      "Iter 300: Saved adapter weights to checkpoints/300_editors.npz.\r\n",
      "Iter 310: Train loss 1.346, Learning Rate 1.000e-05, It/sec 0.081, Tokens/sec 57.205, Trained Tokens 204429\r\n",
      "Iter 320: Train loss 1.311, Learning Rate 1.000e-05, It/sec 0.087, Tokens/sec 51.852, Trained Tokens 210397\r\n",
      "Iter 330: Train loss 1.398, Learning Rate 1.000e-05, It/sec 0.085, Tokens/sec 54.920, Trained Tokens 216829\r\n",
      "Iter 340: Train loss 1.370, Learning Rate 1.000e-05, It/sec 0.091, Tokens/sec 57.985, Trained Tokens 223184\r\n",
      "Iter 350: Train loss 1.099, Learning Rate 1.000e-05, It/sec 0.088, Tokens/sec 55.375, Trained Tokens 229472\r\n",
      "Iter 360: Train loss 1.325, Learning Rate 1.000e-05, It/sec 0.061, Tokens/sec 44.221, Trained Tokens 236775\r\n",
      "Iter 370: Train loss 1.140, Learning Rate 1.000e-05, It/sec 0.095, Tokens/sec 56.221, Trained Tokens 242704\r\n",
      "Iter 380: Train loss 1.195, Learning Rate 1.000e-05, It/sec 0.091, Tokens/sec 53.397, Trained Tokens 248601\r\n",
      "Iter 390: Train loss 1.655, Learning Rate 1.000e-05, It/sec 0.057, Tokens/sec 49.824, Trained Tokens 257341\r\n",
      "Iter 400: Train loss 1.144, Learning Rate 1.000e-05, It/sec 0.112, Tokens/sec 59.800, Trained Tokens 262675\r\n",
      "Iter 400: Val loss 1.406, Val took 141.987s\r\n",
      "Iter 400: Saved adapter weights to checkpoints/400_editors.npz.\r\n",
      "Iter 410: Train loss 1.220, Learning Rate 1.000e-05, It/sec 0.090, Tokens/sec 55.037, Trained Tokens 268819\r\n",
      "Iter 420: Train loss 1.454, Learning Rate 1.000e-05, It/sec 0.073, Tokens/sec 51.010, Trained Tokens 275828\r\n",
      "Iter 430: Train loss 1.195, Learning Rate 1.000e-05, It/sec 0.081, Tokens/sec 55.343, Trained Tokens 282670\r\n",
      "Iter 440: Train loss 1.251, Learning Rate 1.000e-05, It/sec 0.078, Tokens/sec 49.881, Trained Tokens 289097\r\n",
      "Iter 450: Train loss 1.176, Learning Rate 1.000e-05, It/sec 0.080, Tokens/sec 50.116, Trained Tokens 295391\r\n",
      "Iter 460: Train loss 1.249, Learning Rate 1.000e-05, It/sec 0.070, Tokens/sec 48.412, Trained Tokens 302328\r\n",
      "Iter 470: Train loss 1.134, Learning Rate 1.000e-05, It/sec 0.105, Tokens/sec 59.645, Trained Tokens 308020\r\n",
      "Iter 480: Train loss 1.295, Learning Rate 1.000e-05, It/sec 0.075, Tokens/sec 52.581, Trained Tokens 315053\r\n",
      "Iter 490: Train loss 1.182, Learning Rate 1.000e-05, It/sec 0.093, Tokens/sec 58.488, Trained Tokens 321354\r\n",
      "Iter 500: Train loss 1.344, Learning Rate 1.000e-05, It/sec 0.082, Tokens/sec 52.577, Trained Tokens 327745\r\n",
      "Iter 500: Saved adapter weights to checkpoints/500_editors.npz.\r\n",
      "Iter 510: Train loss 1.183, Learning Rate 1.000e-05, It/sec 0.073, Tokens/sec 52.934, Trained Tokens 335029\r\n",
      "Iter 520: Train loss 1.449, Learning Rate 1.000e-05, It/sec 0.067, Tokens/sec 51.610, Trained Tokens 342699\r\n",
      "Iter 530: Train loss 1.332, Learning Rate 1.000e-05, It/sec 0.078, Tokens/sec 50.195, Trained Tokens 349121\r\n",
      "Iter 540: Train loss 1.293, Learning Rate 1.000e-05, It/sec 0.091, Tokens/sec 54.443, Trained Tokens 355075\r\n",
      "Iter 550: Train loss 1.444, Learning Rate 1.000e-05, It/sec 0.063, Tokens/sec 49.679, Trained Tokens 363018\r\n",
      "Iter 560: Train loss 1.197, Learning Rate 1.000e-05, It/sec 0.073, Tokens/sec 50.547, Trained Tokens 369947\r\n",
      "Iter 570: Train loss 1.257, Learning Rate 1.000e-05, It/sec 0.057, Tokens/sec 44.008, Trained Tokens 377730\r\n",
      "Iter 580: Train loss 1.160, Learning Rate 1.000e-05, It/sec 0.075, Tokens/sec 50.617, Trained Tokens 384486\r\n",
      "Iter 590: Train loss 1.214, Learning Rate 1.000e-05, It/sec 0.102, Tokens/sec 55.789, Trained Tokens 389956\r\n",
      "Iter 600: Train loss 0.879, Learning Rate 1.000e-05, It/sec 0.137, Tokens/sec 61.512, Trained Tokens 394433\r\n",
      "Iter 600: Val loss 1.367, Val took 137.833s\r\n",
      "Iter 600: Saved adapter weights to checkpoints/600_editors.npz.\r\n",
      "Saved final adapter weights to editors.npz.\r\n"
     ]
    }
   ],
   "source": [
    "from mlx_lm.utils import get_model_path\n",
    "import os\n",
    "os.environ['MODEL_NAME'] = model_name = 'mlx-community/quantized-gemma-7b-it'\n",
    "\n",
    " \n",
    "!python -m mlx_lm.lora \\\n",
    "    --model \"$MODEL_NAME\" \\\n",
    "    --adapter-file \"editors.npz\" \\\n",
    "    --train \\\n",
    "    --iters 600 --batch-size 1 --lora-layers 4 \\\n",
    "    --data data/editors/gemma"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T19:40:14.555110Z",
     "start_time": "2024-03-02T15:14:52.368721Z"
    }
   },
   "id": "a9da1ee7b6cc7997"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Iter 600: Val loss 1.367, Val took 137.833s"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d5ea07d81750fed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57f675d7cdfd2965"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eceea48ae37a4b75be5f13369be5ff9f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model\r\n",
      "Fetching 8 files: 100%|████████████████████████| 8/8 [00:00<00:00, 42799.02it/s]\r\n",
      "Total parameters 1999.547M\r\n",
      "Trainable parameters 1.835M\r\n",
      "Loading datasets\r\n",
      "Testing\r\n",
      "Test loss 1.395, Test ppl 4.035.\r\n"
     ]
    }
   ],
   "source": [
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "os.environ['MODEL_PATH'] = str(get_model_path(model_name))\n",
    "!python -m mlx_lm.lora \\\n",
    "    --model \"$MODEL_NAME\" \\\n",
    "    --adapter-file \"editors.npz\" \\\n",
    "    --data data/editors/gemma \\\n",
    "    --test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-03T10:30:03.579158Z",
     "start_time": "2024-03-03T10:21:41.778749Z"
    }
   },
   "id": "de978facc2c3c978"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test loss 1.395, Test ppl 4.035."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a39b638de1705a79"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the fine-tuned model with LoRA weights\n",
    "model_lora, _ = load(\n",
    "    \"mlx-community/quantized-gemma-7b-it\",\n",
    "    adapter_file=\"./editors.npz\",  # adapters.npz is the final checkpoint saved at the end of training\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a0a937fa126c7ad"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
