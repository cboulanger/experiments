{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Finetuning experiment: Extract structured data for German law journal editors from website text\n",
    "\n",
    "based on https://github.com/ml-explore/mlx-examples/tree/main/lora\n",
    "\n",
    "Hardware: Mac mini 2023 (M2, 16 GB RAM)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6264ff5d5024ba1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create training data \n",
    "\n",
    "### Download website data\n",
    "\n",
    "This only downloads new content if the list of journals has been changed or already downloaded files have been deleted. To overwrite existing files, use `overwrite=True`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1135fbc8a6ced279"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading Content:   0%|          | 0/130 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7470149ad0534f15bc7158770475355c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 0 web pages.\n"
     ]
    }
   ],
   "source": [
    "from lib.prepare_training_data import download_input_data\n",
    "download_input_data(input_file='data/editors.csv', \n",
    "                    output_dir='data/website-data', \n",
    "                    overwrite=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T09:49:56.822042Z",
     "start_time": "2024-02-28T09:49:56.780283Z"
    }
   },
   "id": "9eb2effc7bfb22f"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from lib.prepare_training_data import create_training_file\n",
    "\n",
    "instruction = \"Below is the content of a website of a German law journal. For each member of the editorial board or the advisory board, extract the following information: lastname, firstname, title, position, affiliation, role. Return as a YAML list of dictionaries. Omit keys that you cannot find information for.\"\n",
    "\n",
    "create_training_file(instruction=instruction,\n",
    "                     input_file='data/editors.csv', \n",
    "                     output_dir='data', \n",
    "                     website_dir='data/website-data',\n",
    "                     max_chars=6000, max_gt_items=5,\n",
    "                     cols_to_remove = ['journal_abbr', 'website', 'retrieved_on'],\n",
    "                     column_to_filter_by='lastname',\n",
    "                     lines_before=2, lines_after=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T17:48:06.013359Z",
     "start_time": "2024-02-28T17:48:03.851056Z"
    }
   },
   "id": "31a2389404720256"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## mistralai/Mistral-7B-v0.1\n",
    "\n",
    "### Create a 4-Bit quantized model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a52bdff5b0eae3bd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python convert.py --hf-path mistralai/Mistral-7B-v0.1 -q"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdb9ec6772be0c23"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train finetuned adapter "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c46d1d132de28c3"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model\r\n",
      "Total parameters 1242.763M\r\n",
      "Trainable parameters 0.426M\r\n",
      "Loading datasets\r\n",
      "Training\r\n",
      "^C\r\n"
     ]
    }
   ],
   "source": [
    "!python lora.py --train \\\n",
    "    --model mlx_model/Mistral-7B-v0.1 \\\n",
    "    --data data/editors \\\n",
    "    --adapter-file mlx_model/Mistral-7B-v0.1/editors.npz \\\n",
    "    --iters 600 --batch-size 1 --lora-layers 4 "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T20:13:07.486513Z",
     "start_time": "2024-02-28T20:12:57.374258Z"
    }
   },
   "id": "fd1a48e84474aaea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test the model with adapter"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27ec240d6a886b16"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model\r\n",
      "Total parameters 1244.041M\r\n",
      "Trainable parameters 1.704M\r\n",
      "Loading datasets\r\n",
      "Testing\r\n",
      "Test loss 1.118, Test ppl 3.059.\r\n"
     ]
    }
   ],
   "source": [
    "!python lora.py --test \\\n",
    "    --model mlx_model/Mistral-7B-v0.1 \\\n",
    "    --data data/editors \\\n",
    "    --adapter-file mlx_model/Mistral-7B-v0.1/editors.npz \n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T20:21:25.577972Z",
     "start_time": "2024-02-28T20:16:00.931002Z"
    }
   },
   "id": "a66ab3a823260361"
  },
  {
   "cell_type": "markdown",
   "source": [
    "last result: Test loss 1.118, Test ppl 3.059.\n",
    "\n",
    "ChatGPT tells me that 'the \"Test ppl 3.059\" indicates that the model has a good performance in predicting the next token in the sequence, given the context of previous tokens, with a relatively low level of uncertainty in its predictions.'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bab8168bd116d38"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prompt it with an example"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7e42a5574068ba9"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "prompt=\"\"\"\n",
    "\"### INSTRUCTION \n",
    "You are a data provider, not a chatbot. Your role is to extract information from documents in a structured format. You don't talk about your reasoning or provide any other commentary. It is imperative that you return only the extracted information in the requested format. Only include what is definitively in the document. Do not invent anything.\n",
    "\n",
    "Below is the content of a website of a German law journal. For each member of the editorial board (which can be \"Herausgeber\" or \"Redakteur\" or \"Schriftleitung\" in German) or the advisory board (\"Beirat\"), extract the following information: lastname, firstname, title, position, affiliation, role. `title` means the academic title, such as 'Dr.' or 'Prof. Dr.'. Merge title suffixes such as \"LL.M.\" to the `title` field. `role` is either 'Herausgeber', 'Redaktion', 'Schriftleitung', 'Beirat' or is not set if unknown. \n",
    "\n",
    "Return as a YAML list of dictionaries. Omit keys that you cannot find information for. Return only strictly valid YAML.\n",
    "\n",
    "### CONTENT\n",
    "\n",
    "Herausgeber:\n",
    "Prof. Dr. Stefan Knesebeck, Universität Wuppertal\n",
    "Prof. Dr. Dr. h.c. Fritz M. Müller LL.M.(Yale), Universität Wanne-Eickel\n",
    "RA Prof. Dr. Vera Valentin, Hochschule für Recht und Sport Edingen\n",
    "Prof. Dr. Dr. h.c. Rita Rosenbaum, Universität Tupfingen\n",
    "Dr. Ingo Gonzalo de Sanchez, Vorsitzender Richter am Oberlandesgericht Rostock\n",
    "Redaktion:\n",
    "RA Adam Gengelbach, Unterhachingen\n",
    "Ass. iur. Petra Priem, Herrenchiemsee\n",
    "\n",
    "### ANSWER\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T08:33:50.360959Z",
     "start_time": "2024-02-29T08:33:50.358199Z"
    }
   },
   "id": "8d316a1e7570f1d4"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- lastname: Knesebeck\r\n",
      "  firstname: Stefan\r\n",
      "  title: Prof. Dr.\r\n",
      "  position: Universität Wuppertal\r\n",
      "  affiliation: Herausgeber\r\n",
      "  role: Herausgeber\r\n",
      "- lastname: Müller\r\n",
      "  firstname: Fritz M.\r\n",
      "  title: Prof. Dr. Dr. h.c.\r\n",
      "  position: Universität Wanne-Eickel\r\n",
      "  affiliation: Herausgeber\r\n",
      "  role: Herausgeber\r\n",
      "- lastname: Rosenbaum\r\n",
      "  firstname: Rita\r\n",
      "  title: Prof. Dr. Dr. h.c.\r\n",
      "  position: Universität Tupfingen\r\n",
      "  affiliation: Herausgeber\r\n",
      "  role: Herausgeber\r\n",
      "- lastname: Sanchez\r\n",
      "  firstname: Gonzalo de\r\n",
      "  title: Dr.\r\n",
      "  position: Vorsitzender Richter am Oberlandesgericht Rostock\r\n",
      "  affiliation: Herausgeber\r\n",
      "  role: Herausgeber\r\n",
      "- lastname: Gengelbach\r\n",
      "  firstname: Adam\r\n",
      "  position: Redaktion\r\n",
      "  affiliation: Redaktion\r\n",
      "  role: Redaktion\r\n",
      "- lastname: Priem\r\n",
      "  firstname: Petra\r\n",
      "  position: Ass. iur.\r\n",
      "  affiliation: Redaktion\r\n",
      "  role: Redaktion\r\n",
      "  \"\r\n",
      "\r\n",
      "import os\r\n",
      "import sys\r\n",
      "import json\r\n",
      "import yaml\r\n",
      "import re\r\n",
      "import ast\r\n",
      "import astunparse\r\n",
      "import astor\r\n",
      "import astorc\r\n",
      "import astunparse\r\n",
      "import astunparse\r\n",
      "import astor\r\n",
      "import astorc\r\n",
      "import astunparse\r\n",
      "import astor\r\n",
      "import astunparse\r\n",
      "import astor\r\n",
      "import astunparse\r\n",
      "import astor\r\n",
      "import astunparse\r\n",
      "import astor\r\n",
      "import astunparse\r\n",
      "import astor\r\n",
      "import astunparse\r\n",
      "Generation took 72.92329788208008 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "os.environ['LLM_PROMPT'] = prompt\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "start_time = time.time()\n",
    "!python lora.py \\\n",
    "    --model mlx_model/Mistral-7B-v0.1 \\\n",
    "    --data data/editors \\\n",
    "    --adapter-file mlx_model/Mistral-7B-v0.1/editors.npz \\\n",
    "    --max-tokens 400 \\\n",
    "    --temp 0 \\\n",
    "    --prompt \"$LLM_PROMPT\"\n",
    "print(f'Generation took {time.time() - start_time} seconds')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T08:41:59.510002Z",
     "start_time": "2024-02-29T08:40:46.438675Z"
    }
   },
   "id": "1ea4b39f35c09268"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## mlx-community/quantized-gemma-7b-it"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1b0c8c8648906b7"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a229bb7e24b3445fa000e2b8f9b6ec81"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```yaml\n",
      "- lastname: Knesebeck\n",
      "  firstname: Stefan\n",
      "  title: Prof. Dr.\n",
      "  position:\n",
      "  affiliation: Universität Wuppertal\n",
      "  role:Herausgeber\n",
      "\n",
      "- lastname: Müller\n",
      "  firstname: Dr. Dr. h.c. Fritz M.\n",
      "  title: Prof. Dr. LL.M.(Yale)\n",
      "  position:\n",
      "  affiliation: Universität Wanne-Eickel\n",
      "  role:Herausgeber\n",
      "\n",
      "- lastname: Valentin\n",
      "  firstname: RA Prof. Dr. Vera\n",
      "  title: Prof. Dr.\n",
      "  position:\n",
      "  affiliation: Hochschule für Recht und Sport Edingen\n",
      "  role:Herausgeber\n",
      "\n",
      "- lastname: Rosenbaum\n",
      "  firstname: Prof. Dr. Dr. h.c. Rita\n",
      "  title: Prof. Dr.\n",
      "  position:\n",
      "  affiliation: Universität Tupfingen\n",
      "  role:Herausgeber\n",
      "\n",
      "- lastname: Gonzalo de Sanchez\n",
      "  firstname: Dr. Ingo\n",
      "  title:\n",
      "  position: Vorsitzender Richter am Oberlandesgericht Rostock\n",
      "  role:\n",
      "\n",
      "- lastname: Gengelbach\n",
      "  firstname: RA Adam\n",
      "  title:\n",
      "  position:\n",
      "  affiliation: Unterhachingen\n",
      "  role:\n",
      "\n",
      "- lastname: Priem\n",
      "  firstname: Ass. iur. Petra\n",
      "  title:\n",
      "  position:\n",
      "  affiliation: Herrenchiemsee\n",
      "  role:\n",
      "```\n",
      "\n",
      "This is the requested output. Please extract the requested\n",
      "Generation took 35.79903483390808 seconds\n"
     ]
    }
   ],
   "source": [
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "from mlx_lm import load, generate\n",
    "import time\n",
    "\n",
    "model, tokenizer = load(\"mlx-community/quantized-gemma-7b-it\")\n",
    "start_time = time.time()\n",
    "response = generate(model, tokenizer, prompt=prompt, verbose=False, max_tokens=300)\n",
    "print(response)\n",
    "print(f'Generation took {time.time() - start_time} seconds')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T08:38:10.003959Z",
     "start_time": "2024-02-29T08:37:23.119783Z"
    }
   },
   "id": "89e1a05fc3b6e435"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d21183bc0271340a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
